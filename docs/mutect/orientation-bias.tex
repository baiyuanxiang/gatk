\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

%% Sets page since and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{bm}
\usepackage{amsfonts}

% Note the substitute command needs to be enclosed in double brackets
% otherwise the bold font spills out of the command
\newcommand{\vzero}{{\bf 0}}
\newcommand{\va}{{\bf a}}
\newcommand{\vI}{{\bf I}}
\newcommand{\vb}{{\bf b}}
\newcommand{\vd}{{\bf d}}
\newcommand{\vf}{{\bf f}}
\newcommand{\vc}{{\bf c}}
\newcommand{\vp}{{\bf p}}
\newcommand{\vv}{{\bf v}}
\newcommand{\vz}{{\bf z}}
\newcommand{\vn}{{\bf n}}
\newcommand{\vm}{{\bf m}}
\newcommand{\vG}{{\bf G}}
\newcommand{\vQ}{{\bf Q}}
\newcommand{\vM}{{\bf M}}
\newcommand{\vW}{{\bf W}}
\newcommand{\vX}{{\bf X}}
\newcommand{\vPsi}{{\bf \Psi}}
\newcommand{\vSigma}{{\bf \Sigma}}
\newcommand{\vlambda}{{\bf \lambda}}
\newcommand{\vpi}{{\bm \pi}}
\newcommand{\vtheta}{{\bm \theta}}
\newcommand{\valpha}{{\bm{\alpha}}}
\newcommand{\vLambda}{{\bf \Lambda}}
\newcommand{\vA}{{\bf A}}
\newcommand{\E}{\mathbb{E}}



\title{Mutect2 Orientation Artifact Filter}
\author{Takuto Sato}


\begin{document}
\maketitle

\section{Questions}
\todo[inline, color = green]{Deamination is a $C \mapsto T , G \mapsto A$ artifact. Does it take read orientation into consideration?}

\section{Terminology}
Clearly define:
Forward strand
Reverse strand

\section{Intro}
We will first discuss how orientation bias arises during sequencing. To do so we will go over Kap ICE library construction (also known as library prep) and a bit of Illumina sequencing. We will abbreviate and abstract the steps along the way to facilitate understanding. 

We first take a vial full of DNA molecules and shear them into fragments. The resulting fragments of DNA, as depicted in the Figure \ref{fig:oxog}, are called \textit{inserts}. Without loss of generality we assume that the strand shown on top in blue is the \textit{forward} strand; that is, read from 5' end to 3' end, bases in the blue strand happen to map directly to the reference. The strand in orange, conversely, is a \textit{reverse} strand, as it is a reverse complement of the reference when read from 5' to 3' end.

Note that, for us, there is nothing magical about the reference bases. Somebody somewhere picked one of the two strands arbitrarily. Given a random piece of DNA, therefore, ... START HERE

Next in library prep we add adapters to the double-stranded inserts. We only use one kind of double-stranded adapter, shown in red and green in Figure \ref{fig:oxog}. What this means is that the clones of the same double-stranded adapter attach to both sides of the insert (they are flipped due to the asymmetry of DNA). Note that the ends of adapters are not base-paired; that is, the sequences on the two strands are not complementary. This will play a crucial role later on. \todo{Must be more specific here} A \textit{library} refers to an insert with adapters attached on both ends. We will subsequently make many copies of each \textit{original library} via PCR.

PCR replicates of the forward strand are shown on the bottom left corner in the figure. Note that during PCR G* in the forward strand base paired with A, which, after another round of PCR, created a third duplicate with a T in place of the original G. PCR replicates the reverse strand, shown in deep orange, faithfully and thus we get only one type of PCR duplicate\footnote{in reality this is unlikely. But since we are talking about an idealized, abstracted world anyway, we are free to suppose that this is the case}. 

Few years back, folks at GP found that high-power acoustic shearing (as opposed to enzymatic shearing as in Nexome Library Construction) may cause guanine (G) in an insert to oxidize. The oxidized G may base-pair with adenine (A) in addition to the regular cytosine (C). The oxidized G is depicted as a G* with an asterisk in the figures; thus the forward strand at the top of the figure contains an oxidized G near the 5' end.

Now we pour the libraries on the flowcell, as detailed in Figure \ref{fig:flowcell}. 

%%%%%
 
 \section{Scrap yard of things that may be crap}
 
Couple things to note about the adapters; adapters are not symmetric. That is, once adapter is ligated, the two strands in the double stranded insert molecule behave differently. Namely, the way adapter is ligated to the DNA decides which strand, forward or reverse, will be sequenced first. This means that we can sequence the same molecule two different ways, depending on how the adapter is ligated; read the forward strand first, or read the reverse strand first. This happens at random. We mark the read pair in the former case to have F1R2 orientation and the latter F2R1. Since the adapter ligation happens at random, we should see about an equal amount of F1R2 and F2R1 reads. For a fixed insert, the way adapter is ligated does not affect which sequences are read. 

Orientation bias is a form of sequencing artifact in which the alternate allele occurs exclusively in F1R2 reads or F2R1 reads. Since the orientation of reads should be balanced - as we have no reason to believe that the adapter prefers to ligate one way over the other - the skew in read orientation e.g. evidence for SNP all comes from F1R2 reads leads us to suspect the call.

A similar but different mode of artifact is strand bias. Strand bias is in essence a bias in choosing the DNA insert (e.g. at the end of a bait). As mentioned previously, fixing an insert fixes which part of the insert is read, as well as how these reads map to the reference (i.e. forward or reverse). (NOTE: this is not specifically the bias that we are worried about, but rather this explains why at the end of bait intervals we have more reads, ref or alt, in one direction over the other). (Here comes the more relevant point) we can imagine that in certain reference contexts reading in one direction is harder than the doing so in the other direction. For instance, in the reference context 5'-AAAAGTACG-3', reading from the left one must read a bunch of A's, which we know is difficult and confusing to the machine, whereas reading from the right (on the other strand) is easier. Here, one can imagine the case where the sequencer makes an error and introduces a SNP only when it reads the sequence left to right. 

At a given locus, whether the read overlapping the locus is a reverse or forward read is a function of the position of the insert relative to the reference. That is, once you fix a locus and an insert that overlaps it, you know whether the read that overlaps the locus will be reverse or forward. Fixing a locus and an insert does not give you any information about the read orientation. It may be F1R2 or R2F1, 

We then ligate adapters to this double stranded DNA. The way we 


\begin{figure}
  \includegraphics[width=\linewidth]{oxog.pdf}
  \caption{Library }
  \label{fig:oxog}
\end{figure}


\begin{figure}
  \includegraphics[width=\linewidth]{quadrants.pdf}
  \caption{(Top) We may divide the original library into quadrants and consider individually the cases where the oxoG takes place in each quadrant. (Bottom, top left) Oxog in the first quadrant (I). (Bottom, top right) Oxog in the second quadrant (II). (Bottom, bottom right) third quadrant (III) and (Bottom, bottom left) fourth quadrant (IV) }
  \label{fig:quadrants}
\end{figure}

\begin{figure}
  \includegraphics[width=\linewidth]{flowcell.pdf}
  \caption{(Left) By virtue of the 3' end of the original adapter (in deep red) containing sequence complementary to the oligo tethered to the flow cell (P7), the strands in the original library, not the strands filled in by PCR, will be read first, as shown on the right panel of the figure. That is, the sequencer synthesizes and fluoresces the bases in the original library first. Here, Read1 will read a T in the forward strand, where the reference has G. Thus the read will have a G -> T substitution. }
  \label{fig:flowcell}
\end{figure}


\section{Oxog}

Oxog, for our purposes, is a process in which guanine (G-base) is oxidized and is able to base pair with adenine (A) instead of the usual cytosine (C). We know that this takes place somewhere in the process of sequencing the DNA in the lab. Suppose that an adapter-ligated DNA insert is oxidized to oxoG. This may happen on a forward strand or on a reverse strand. Consider the case in which it occurs in the forward strand, and call this $x$. When we sequence $x$, it gets ligate to the oligo tethered to the flow cell, and we base pair the rest. At the end we get the reverse complement of $x$, call it $x'$, tethered to the flowcell. Thanks to the oxidized $G$ in $x$, $x'$ contains an $A$ where it would normally have a $C$. Now we bind the primer to the read 1 primer binding site in $x'$, and we read off the bases. Where we should have read $G$, we will read a $T$. An artifact. Notice that we read the forward read first, so this read is F1R2.

Why wouldn't this artifact appear in a F2R1 read? Well, to have an F2R1 read

\subsection{How PCR multplies inserts with oxog}


\section{The probabilistic model}

Our probabilistic graphical model is in Figure (\ref{fig:pgm}). For each reference context $c$ - that is, for every $k$-mer in the reference - the discrete latent variable $z$ represents the state of the site with respect to the degree of orientation-bias 

\begin{equation*}
z \in \{ \text{F1R2}, \text{F2R1}, \text{Balanced Hom Ref}, \text{Balanced Het}, \text{Balanced Hom Var} \}
\end{equation*}

$z \sim \mathrm{Categorical}(\vpi^a_c)$, where $\pi^a_{ck}$ is the context dependent prior probability of the kth component of $z$ given allele $a$ and satisfies $\sum_k \pi^a_{ck} = 1$, where $k \in [1, |Z|]$. The number of alt alleles at the site, $m$, is a binomial random variable whose probability of success $f$ (i.e. allele fraction) depends on the state $z$. We explicitly model the number of alt alleles because its dependence on $z$ encapsulates our knowledge that, when orientation bias is present, we \textit{always} have (artifactual) alt reads at the site. In other words, if we do not observe alt reads at all (i.e. $z = \mathrm{Hom ref}$), we cannot have orientation bias at the site. \todo[inline, color = green]{This is not a valid asusmption i.e. We cannot assume that $m = 0$ and $z = \text{hom ref}$ go together. Rather, we must design the model such that this is the case. That is, we give it a very low likelihood when $m = 0$ and $z$ is anything other than hom ref.}

We then model the number of $F1R2$ reads among $m$ alt reads as $x|m,z \sim \mathrm{Binom(\vtheta_z)}$, parameterized by $\theta_z$ that depends on whether the site suffers from orientation bias. In other words, $\theta$ depends on $z$. 

\begin{itemize}
\item $z \sim \mathrm{Categorical}(\vpi^a_c)$
\item $m | z \sim \mathrm{Binom(f_z)}$
\item $x | m,z \sim \mathrm{Binom(\vtheta_z)}$
\end{itemize}

\begin{figure}
\centering
\includegraphics[width=0.3\textwidth]{pgm.png}
\caption{\label{fig:pgm} The probabilistic graphical model for the orientation bias filter}
\end{figure}

% TODO: What does the model know? What doesn't it know? The model does not know about the normal sample. If there's a low allele fraction variant in 
% Work on my strength, not weaknesses. 

%%%
\subsection{EM algorithm}
We estimate the hyperparameters $\vpi$ and $\vp$ that maximize likelihood using the EM algorithm. We can then compute the posterior probability of the latent variable $z$ to determine whether a variant is an orientation artifact and thus should be filtered.

\subsubsection{E step}
In the E step, we compute the responsibilities $\gamma_{nk} = p(z_{nk} | x_n, m_n, a)$. $\gamma_{nk}$ is the posterior probability of $k$th component of $z$ given random variables $x_n$ and $m_n$ and allele $a$. By Bayes rule we have \todo[inline]{Don't we need the binomial constants?}

\begin{align}
\gamma^*_{nk} &\propto p(z_{nk} | x_n, m_n, a) \nonumber \\
		        &\propto p(z_{nk} | a) p(m_n | z_{nk}, f_{k} ) p(x_n | m_n ) \nonumber \\
		        &= \pi_{ak}  \{ f_{k}^{m_n} (1-f_k)^{R - m_n} \} \{ \theta_k^{x_n} (1 - \theta_k)^{m_n - x_n} \}
\end{align}


where $R$ is the number of reads at site $n$, and the asterisk over $\gamma^*_{nk}$ denotes that the responsibility is not normalized and thus is not a probability. Normalizing responsibilities gives us

\begin{align}
\gamma_{nk} = \frac{\gamma^*_{nk}}{\sum_{k'} \gamma^*_{nk'}}
\end{align}

Make a mention of the allele lurking in the background here. The allele $a$, a deterministic parameter, much like the depth, picks out the appropriate $\pi$ estimates for us.  \todo{Refine this explanation}. 

\subsubsection{M step}
In the M step, we maximize the expectation of the complete-data log likelihood with respect to the posterior distribution over $z$ (so $\E$ is a shorthand for $\E_{Z \sim p(Z|X,M)}$). We may read the form of the complete-data log likelihood $p(X, M, Z | \vpi, \vp, \vtheta)$ from the graphical model, and its expectation is

\begin{align}
\E [ \ln p(X, M , Z | \vpi, \vp, \vtheta, \va) ] &= \E [ \ln \prod_{n = 1}^{N}  p(z_n | a_n) p(m_n | z_n, p_{z} ) p(x_n | m_n, z_n, \theta_n ) ] \nonumber \\
							&= \E [ \ln \prod_{n = 1}^{N} \{ \prod_{k = 1}^{K} \pi_{ak}^{z_{nk}} \} \{ \prod_{k = 1}^{K} ( f_k^{m_n} (1-f_k)^{R_n - m_n} ) ^{z_{nk}} \} \{ \prod_{k = 1}^{K} ( \theta_k^{x_n} (1 - \theta_k)^{m_n - x_n} )^{z_{nk}} \} ] \notag \\
							&= \E [ \ln \prod_{n = 1}^{N} \prod_{k = 1}^{K} \{ \pi_{ak}  f_{k}^{m_n} (1-f_k)^{R_n - m_n} \theta_k^{x_n} (1 - \theta_k)^{m_n - x_n} \}^{z_{nk}} ]  \nonumber \\
							&= \E [ \sum_{n = 1}^{N} \sum_{k = 1}^{K} z_{nk} \{ \ln \pi_{ak}  + m_n \ln f_k + (R_n - m_n) \ln (1-f_k) + \notag \\
							&\phantom{---------------} x_n \ln \theta_k + (m_n - x_n) \ln (1 - \theta_k) \} ]  \nonumber \\
							&= \sum_{n = 1}^{N} \sum_{k = 1}^{K} \gamma_{nk} \{ \ln \pi_{ak}  + m_n \ln f_k + (R_n - m_n) \ln (1-f_k) + \notag \\
						    &\phantom{---------------} x_n \ln \theta_k + (m_n - x_n) \ln (1 - \theta_k) \label{eq:expjointLL} \}
\end{align} 

where $K = |Z|$, $X$ is the design matrix whose $n$th row is $x_n$ ($M$ and $Z$ are defined analogously), and $\E [ z_{nk} ] = \gamma_{nk}$. We define the following terms to simplify the expected complete-data log likelihood.

\begin{align}
N_k      &= \sum_n \gamma_{nk} \label{eq:nk} \\
N_{ak}      &= \sum_{n : a_n = a} \gamma_{nk} \label{eq:nk} \\
\bar{x}_k  &= \frac{1}{N_k} \sum_n \gamma_{nk} x_n \label{eq:xbar} \\
\bar{m}_k &= \frac{1}{N_k} \sum_n \gamma_{nk} m_n \label{eq:mbar} \\
\bar{R}_k  &= \frac{1}{N_k} \sum_n \gamma_{nk} R_n \label{eq:Rbar}
\end{align}

$N_k$ is the effective number of samples in state $z_k$, and $N_{ak}$ the effective number of samples that are in state $z_k$ \textit{and} have allele $a$. $\bar{x}_k$ and $\bar{m}_k$ are the effective sample means of $x$ and $m$ weighted by the each sample's responsibility in explaining the state $z_k$, and $\bar{R}_k$ is the effective mean depth over the sites in state $z_k$. 

We now take the derivative of (\ref{eq:expjointLL}) with respect to $\theta_k, p_k, \pi_{ak}$, set them equal to 0, and solve for those parameters to get the update equations.

\begin{align}
\frac{\partial}{\partial \theta_k} \E [ \ln p(X, M , Z | \vpi, \vp, \vtheta, \va) ] &= \sum_n \gamma_{nk} \Big( \frac{ x_n}{\theta_k} - \frac{m_n - x_n}{1- \theta_k} \Big)\\
					         							     &= \frac{N_k \bar{x}_k}{\theta_k} - \frac{N_k \bar{m}_k - N_k \bar{x}_k}{1- \theta_k} = 0
\end{align}

where we used (\ref{eq:xbar}) and (\ref{eq:mbar}). Solving for $\theta_k$, we get

\begin{align}
\hat{\theta}_k = \frac{\bar{x}_k}{\bar{m}_k} \label{eq:theta}
\end{align}

Thus we update $\theta$ to the fraction of F1R2 alt reads, counting only those examples that belong to class $k$ according to the current estimate for responsibilities. Derivative with respect to $f_k$ is completely analogous:

\begin{align}
\hat{f}_k = \frac{\bar{m}_k}{\bar{R}_k} \label{eq:f}
\end{align}

Finally we take the derivative with respect to $\pi_{ak}$ under the constraint $\sum_k \pi_{ak} = 1$. Using a Lagrange multiplier to account for the constraint, we get

\begin{align}
\frac{\partial}{\partial \pi_{ak}} \{ \E [ \ln p(X, M , Z | \vpi, \vp, \vtheta) ] + \lambda ( \sum_k \pi_{ak} - 1)\} &= \sum_{n : a_n = a} \frac{\gamma_{nk}}{\pi_{ak}} + \lambda \nonumber \\
																   &= \frac{N_{ak}}{\pi_{ak}} + \lambda = 0 \label{eq:dpi}
\end{align}

where $\lambda$ is the Lagrange multiplier. Rearranging (\ref{eq:dpi}) and summing over $k$, we get

\begin{align*}
\sum_k N_{ak} &= \sum_k - \lambda \pi_{ak} \\
      \lambda &= - N_a 
\end{align*}

where $N_a = \sum_k N_{ak} $ is the number of observed sites with allele $a$. Plugging in for $\lambda$ in (\ref{eq:dpi}) gives us

\begin{equation}
\hat{\pi}_{ak} = \frac{N_{ak}}{N_a}
\end{equation}

% TODO: Discuss the forms of these update equations
% Initialize parameters, and iterate E and M-steps.



%%%%%%%%%%
\section{July 14th meeting with David}

When building a model, we'd like to know what information the model knows about. The previous model knew that 

\begin{itemize}
\item the probability of orientation bias depends on context
\item if orientation bias, most \underline{alt} reads have one or the other orientation
\end{itemize}

But the model did not know, crucially, that if there's orientation bias, there must be some alt reads. Since we were looking at sites that have alt reads, the model didn't know 

We then decided to add the variable $m$ to the model.  Once the model was updated, we went over different scenarios: what would happen if 
\begin{itemize}
\item $n = 100, m = 10, x = 5$ 
\item $n = 100, m = 1, x = 1$
\item $n = 100, m = 0, x = 0$
\end{itemize}

How does each part of the model vote, so to speak, for or against such data? The different components are $p(m|z), p(x|m), p(z | \pi)$. The first case rules 
When the later likelihoods don't favor one of the other, the final vote falls on $p(z | \pi)$ which, assuming we already have the hyperparameters learned over all sites, uses the prior across all sites to vote one way or another. That is, when data is not very informative, when it doesn't tell us one way or another, we use the prior knowledge to make the decision, which makes sense.

When mean field theory is used, the conjugacy across nodes is not crucial. Conjugacy between immediate neighbors makes life easier.

$m$ could be binomial. Or it could be beta-binomial. Beta-binomial has larger spread when $n$ is large or something. 

At one point I suggested that $m|z = \mathrm{no bias}$ be a mixture, between somatic variant (where $m$ can be large) or hom ref (where $m$). Instead I could just add more values to the $z$ variable such that $z \in \{ \text{F1R2}, \text{F2R1}, \text{Balanced Hom Ref}, \text{Balanced Somatic}, \text{Germline} \}$.

%%%%%%%%%%
\section{Previous approach, and why my filter is better}
\begin{itemize}
\item The old tool adds up the count of pro, con, ref, alt for each transition over different contexts, so if there's any context-specific information we lose it.
\item 
\end{itemize}




\end{document}